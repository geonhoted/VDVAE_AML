{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgyz6Akontiz"
      },
      "source": [
        "# model_hps.py\n",
        "\n",
        "VDVAE의 encoder, decoder 내부 layer 수 및 이미지 설정 등 모델 구조에 관련된 하이퍼파라미터를 여기서 관리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wI5b0eOwn3oY"
      },
      "outputs": [],
      "source": [
        "# we manage parameters for model structure here.\n",
        "encblock_str = \"32x11,32d2,16x6,16d2,8x6,8d2,4x3,4d4,1x3\"   # encoder 구조\n",
        "custom_width_str = \"\"                                       # 해상도별 채널 수 조정 (16:64,8:64)\n",
        "decblock_str = \"1x1,4m1,4x2,8m4,8x5,16m8,16x10,32m16,32x21\" # decoder 구조\n",
        "\n",
        "image_size = 32\n",
        "image_channels = 3\n",
        "base_width = 384\n",
        "bottleneck_multiple = 0.25\n",
        "zdim = 16\n",
        "num_mixtures = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PvpJUvWnlf5"
      },
      "source": [
        "# hps.py\n",
        "\n",
        "모델의 학습 관련 및 저장소, 데이터 루트 등의 하이퍼파라미터는 모두 여기 모아서 관리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6X9voPCj44H"
      },
      "outputs": [],
      "source": [
        "HPARAMS_REGISTRY = {}\n",
        "\n",
        "class Hyperparams(dict):\n",
        "    def __getattr__(self, attr):\n",
        "        try:\n",
        "            return self[attr]\n",
        "        except KeyError:\n",
        "            return None\n",
        "\n",
        "    def __setattr__(self, attr, value):\n",
        "        self[attr] = value\n",
        "\n",
        "\n",
        "# We only use CIFAR-10 dataset\n",
        "cifar10 = Hyperparams()\n",
        "cifar10.dataset = 'cifar10'\n",
        "cifar10.lr = 0.0002\n",
        "cifar10.wd = 0.01\n",
        "cifar10.n_batch = 32\n",
        "cifar10.ema_rate =  0.9998\n",
        "cifar10.warmup_iters = 100\n",
        "cifar10.skip_threshold = 400.0\n",
        "cifar10.max_iters = 1400        # training ends up based on which is longer between max_iters & epoch.\n",
        "cifar10.num_epochs = 1\n",
        "HPARAMS_REGISTRY['cifar10'] = cifar10\n",
        "\n",
        "\n",
        "def parse_args_and_update_hparams(H, parser, s=None):\n",
        "    args = parser.parse_args(s)\n",
        "    valid_args = set(vars(args).keys())\n",
        "\n",
        "    hps = HPARAMS_REGISTRY['cifar10']\n",
        "    for k in hps:\n",
        "        if k not in valid_args:\n",
        "            raise ValueError(f\"{k} not in default args\")\n",
        "    parser.set_defaults(**hps)\n",
        "    args = parser.parse_args(s)\n",
        "    H.update(vars(args))\n",
        "\n",
        "\n",
        "# we manage all parameters here except for model structure.\n",
        "def add_vae_arguments(parser):\n",
        "    parser.add_argument('--seed', type=int, default=0)\n",
        "    parser.add_argument('--port', type=int, default=29500)\n",
        "    parser.add_argument('--save_dir', type=str, default='./saved_models')\n",
        "    parser.add_argument('--data_root', type=str, default='../content')\n",
        "\n",
        "    parser.add_argument('--desc', type=str, default='test')\n",
        "    parser.add_argument('--restore_path', type=str, default=None,\n",
        "                        help=\"checkpoint prefix를 지정하면 그 지점부터 학습을 복원!\")        # default = './saved_models/test/latest'\n",
        "    parser.add_argument('--restore_ema_path', type=str, default=None)                        # default='./saved_models/test/latest'\n",
        "    parser.add_argument('--restore_log_path', type=str, default=None)                        # default='./saved_models/test/latest-log.jsonl'\n",
        "    parser.add_argument('--restore_optimizer_path', type=str, default=None)                  # default='./saved_models/test/latest-opt.th'\n",
        "    parser.add_argument('--dataset', type=str, default='cifar10')\n",
        "\n",
        "    parser.add_argument('--ema_rate', type=float, default=0.999)\n",
        "\n",
        "    parser.add_argument('--test_eval', action=\"store_true\")\n",
        "    parser.add_argument('--warmup_iters', type=float, default=0)\n",
        "\n",
        "    parser.add_argument('--grad_clip', type=float, default=200.0)\n",
        "    parser.add_argument('--skip_threshold', type=float, default=400.0)\n",
        "    parser.add_argument('--lr', type=float, default=0.00015)\n",
        "    parser.add_argument('--lr_prior', type=float, default=0.00015)\n",
        "    parser.add_argument('--wd', type=float, default=0.0)\n",
        "    parser.add_argument('--wd_prior', type=float, default=0.0)\n",
        "    parser.add_argument('--num_epochs', type=int, default=10)                 # 10000 (maximum)\n",
        "    parser.add_argument('--n_batch', type=int, default=32)\n",
        "    parser.add_argument('--adam_beta1', type=float, default=0.9)\n",
        "    parser.add_argument('--adam_beta2', type=float, default=0.9)\n",
        "\n",
        "    parser.add_argument('--temperature', type=float, default=1.0)\n",
        "\n",
        "    parser.add_argument('--iters_per_ckpt', type=int, default=25000)\n",
        "    parser.add_argument('--iters_per_print', type=int, default=1000)\n",
        "    parser.add_argument('--iters_per_save', type=int, default=1500)          # 10000\n",
        "    parser.add_argument('--iters_per_images', type=int, default=10000)\n",
        "    parser.add_argument('--epochs_per_eval', type=int, default=10)            # number of epoch\n",
        "    parser.add_argument('--epochs_per_probe', type=int, default=None)\n",
        "    parser.add_argument('--epochs_per_eval_save', type=int, default=20)\n",
        "    parser.add_argument('--num_images_visualize', type=int, default=10)\n",
        "    parser.add_argument('--num_variables_visualize', type=int, default=7)\n",
        "    parser.add_argument('--num_temperatures_visualize', type=int, default=3)\n",
        "    parser.add_argument('--max_iters', type=int, default=3125)                # number of maximum iterations\n",
        "    return parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZV6kwt5qnut"
      },
      "source": [
        "# data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yBl6pTg8qorY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def set_up_data(H):\n",
        "    shift_loss = -127.5\n",
        "    scale_loss = 1. / 127.5\n",
        "    if H.dataset == 'cifar10':\n",
        "        (trX, _), (vaX, _), (teX, _) = load_cifar10_data(H.data_root, one_hot=False)\n",
        "        H.image_size = 32\n",
        "        H.image_channels = 3\n",
        "        shift = -120.63838\n",
        "        scale = 1. / 64.16736\n",
        "    else:\n",
        "        raise ValueError('unknown dataset: ', H.dataset)\n",
        "\n",
        "    if H.test_eval:\n",
        "        print('DOING TEST')\n",
        "        eval_dataset = teX\n",
        "    else:\n",
        "        eval_dataset = vaX\n",
        "\n",
        "    # Reshape shift, scale, shift_loss, and scale_loss for broadcasting\n",
        "    shift = torch.tensor([shift]).cuda().view(1, 1, 1, 1)\n",
        "    scale = torch.tensor([scale]).cuda().view(1, 1, 1, 1)\n",
        "    shift_loss = torch.tensor([shift_loss]).cuda().view(1, 1, 1, 1)\n",
        "    scale_loss = torch.tensor([scale_loss]).cuda().view(1, 1, 1, 1)\n",
        "\n",
        "\n",
        "    train_data = TensorDataset(torch.as_tensor(trX))\n",
        "    valid_data = TensorDataset(torch.as_tensor(eval_dataset))\n",
        "\n",
        "    def preprocess_func(x):\n",
        "        nonlocal shift\n",
        "        nonlocal scale\n",
        "        nonlocal shift_loss\n",
        "        nonlocal scale_loss\n",
        "        inp = x[0].cuda(non_blocking=True).float()\n",
        "        out = inp.clone()\n",
        "        inp.add_(shift).mul_(scale)\n",
        "        out.add_(shift_loss).mul_(scale_loss)\n",
        "        return inp, out\n",
        "\n",
        "    return H, train_data, valid_data, preprocess_func\n",
        "\n",
        "\n",
        "def unpickle_cifar10(file):\n",
        "    fo = open(file, 'rb')\n",
        "    data = pickle.load(fo, encoding='bytes')\n",
        "    fo.close()\n",
        "    data = dict(zip([k.decode() for k in data.keys()], data.values()))\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_cifar10_data(data_root, one_hot=True):\n",
        "    root = os.path.join(data_root, 'cifar-10-batches-py')\n",
        "\n",
        "    # load training batches\n",
        "    data_list, label_list = [], []\n",
        "    for i in range(1, 6):\n",
        "        batch_path = os.path.join(root, f'data_batch_{i}')\n",
        "        batch = unpickle_cifar10(batch_path)\n",
        "        data_list.append(batch['data'])\n",
        "        label_list.append(batch['labels'])\n",
        "    trX = np.concatenate(data_list, axis=0).astype(np.float32)               # (50000, 3072)\n",
        "    trY = np.concatenate(label_list, axis=0).astype(np.int64)                # (50000,)\n",
        "\n",
        "    # load test batches\n",
        "    test_batch = unpickle_cifar10(os.path.join(root, 'test_batch'))\n",
        "    teX = np.array(test_batch['data'], dtype=np.uint8).astype(np.float32)    # (10000, 3072)\n",
        "    teY = np.array(test_batch['labels'], dtype=np.int64)                     # (10000,)\n",
        "\n",
        "    trX = trX.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "    teX = teX.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "    trX, vaX, trY, vaY = train_test_split(trX, trY, test_size=5000, random_state=11172018)\n",
        "\n",
        "    if one_hot:\n",
        "        trY = np.eye(10, dtype=np.float32)[trY]\n",
        "        vaY = np.eye(10, dtype=np.float32)[vaY]\n",
        "        teY = np.eye(10, dtype=np.float32)[teY]\n",
        "    else:\n",
        "        trY = np.reshape(trY, [-1, 1])\n",
        "        vaY = np.reshape(vaY, [-1, 1])\n",
        "        teY = np.reshape(teY, [-1, 1])\n",
        "    return (trX, trY), (vaX, vaY), (teX, teY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeEYQgGiqq1q"
      },
      "source": [
        "# utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_C90XuuquLq",
        "outputId": "9cf8c4b0-bc67-449a-8c40-28f2c903baba"
      },
      "outputs": [],
      "source": [
        "# !pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZoU0_jUFqv55"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from mpi4py import MPI\n",
        "    import torch.distributed as dist\n",
        "    mpi_available = True\n",
        "except ImportError:\n",
        "    MPI = None\n",
        "    dist = None\n",
        "    mpi_available = False\n",
        "\n",
        "import os\n",
        "import json\n",
        "import socket\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parallel.distributed import DistributedDataParallel\n",
        "from torch.optim import AdamW\n",
        "from collections import defaultdict\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def parse_layer_string(s):\n",
        "    layers = []\n",
        "    for ss in s.split(','):\n",
        "        if 'x' in ss:\n",
        "            res, num = ss.split('x')\n",
        "            count = int(num)\n",
        "            layers += [(int(res), None) for _ in range(count)]\n",
        "        elif 'm' in ss:\n",
        "            res, mixin = [int(a) for a in ss.split('m')]\n",
        "            layers.append((res, mixin))\n",
        "        elif 'd' in ss:\n",
        "            res, down_rate = [int(a) for a in ss.split('d')]\n",
        "            layers.append((res, down_rate))\n",
        "        else:\n",
        "            res = int(ss)\n",
        "            layers.append((res, None))\n",
        "    return layers\n",
        "\n",
        "\n",
        "def pad_channels(t, width):\n",
        "    d1, d2, d3, d4 = t.shape\n",
        "    empty = torch.zeros(d1, width, d3, d4, device=t.device)\n",
        "    empty[:, :d2, :, :] = t\n",
        "    return empty\n",
        "\n",
        "\n",
        "def get_width_settings(width, s):\n",
        "    mapping = defaultdict(lambda: width)\n",
        "    if s:\n",
        "        s = s.split(',')\n",
        "        for ss in s:\n",
        "            k, v = ss.split(':')\n",
        "            mapping[int(k)] = int(v)\n",
        "    return mapping\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def gaussian_analytical_kl(mu1, mu2, logsigma1, logsigma2):\n",
        "    return -0.5 + logsigma2 - logsigma1 + 0.5 * (logsigma1.exp() ** 2 + (mu1 - mu2) ** 2) / (logsigma2.exp() ** 2)\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def draw_gaussian_diag_samples(mu, logsigma):\n",
        "    eps = torch.empty_like(mu).normal_(0., 1.)\n",
        "    return torch.exp(logsigma) * eps + mu\n",
        "\n",
        "\n",
        "def discretized_mix_logistic_loss(x, l, low_bit=False):\n",
        "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
        "    # Adapted from https://github.com/openai/pixel-cnn/blob/master/pixel_cnn_pp/nn.py\n",
        "    xs = [s for s in x.shape]  # true image (i.e. labels) to regress to, e.g. (B,32,32,3)\n",
        "    ls = [s for s in l.shape]  # predicted distribution, e.g. (B,32,32,100)\n",
        "    nr_mix = int(ls[-1] / 10)  # here and below: unpacking the params of the mixture of logistics\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = torch.reshape(l[:, :, :, nr_mix:], xs + [nr_mix * 3])\n",
        "    means = l[:, :, :, :, :nr_mix]\n",
        "    log_scales = const_max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\n",
        "    coeffs = torch.tanh(l[:, :, :, :, 2 * nr_mix:3 * nr_mix])\n",
        "    x = torch.reshape(x, xs + [1]) + torch.zeros(xs + [nr_mix]).to(x.device)  # here and below: getting the means and adjusting them based on preceding sub-pixels\n",
        "    m2 = torch.reshape(means[:, :, :, 1, :] + coeffs[:, :, :, 0, :] * x[:, :, :, 0, :], [xs[0], xs[1], xs[2], 1, nr_mix])\n",
        "    m3 = torch.reshape(means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] + coeffs[:, :, :, 2, :] * x[:, :, :, 1, :], [xs[0], xs[1], xs[2], 1, nr_mix])\n",
        "    means = torch.cat([torch.reshape(means[:, :, :, 0, :], [xs[0], xs[1], xs[2], 1, nr_mix]), m2, m3], dim=3)\n",
        "    centered_x = x - means\n",
        "    inv_stdv = torch.exp(-log_scales)\n",
        "    if low_bit:\n",
        "        plus_in = inv_stdv * (centered_x + 1. / 31.)\n",
        "        cdf_plus = torch.sigmoid(plus_in)\n",
        "        min_in = inv_stdv * (centered_x - 1. / 31.)\n",
        "    else:\n",
        "        plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
        "        cdf_plus = torch.sigmoid(plus_in)\n",
        "        min_in = inv_stdv * (centered_x - 1. / 255.)\n",
        "    cdf_min = torch.sigmoid(min_in)\n",
        "    log_cdf_plus = plus_in - F.softplus(plus_in)  # log probability for edge case of 0 (before scaling)\n",
        "    log_one_minus_cdf_min = -F.softplus(min_in)  # log probability for edge case of 255 (before scaling)\n",
        "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
        "    mid_in = inv_stdv * centered_x\n",
        "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)  # log probability in the center of the bin, to be used in extreme cases (not actually used in our code)\n",
        "\n",
        "    # now select the right output: left edge case, right edge case, normal case, extremely low prob case (doesn't actually happen for us)\n",
        "\n",
        "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
        "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.log(cdf_delta)))\n",
        "\n",
        "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
        "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
        "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
        "    if low_bit:\n",
        "        log_probs = torch.where(x < -0.999,\n",
        "                                log_cdf_plus,\n",
        "                                torch.where(x > 0.999,\n",
        "                                            log_one_minus_cdf_min,\n",
        "                                            torch.where(cdf_delta > 1e-5,\n",
        "                                                        torch.log(const_max(cdf_delta, 1e-12)),\n",
        "                                                        log_pdf_mid - np.log(15.5))))\n",
        "    else:\n",
        "        log_probs = torch.where(x < -0.999,\n",
        "                                log_cdf_plus,\n",
        "                                torch.where(x > 0.999,\n",
        "                                            log_one_minus_cdf_min,\n",
        "                                            torch.where(cdf_delta > 1e-5,\n",
        "                                                        torch.log(const_max(cdf_delta, 1e-12)),\n",
        "                                                        log_pdf_mid - np.log(127.5))))\n",
        "    log_probs = log_probs.sum(dim=3) + log_prob_from_logits(logit_probs)\n",
        "    mixture_probs = torch.logsumexp(log_probs, -1)\n",
        "    return -1. * mixture_probs.sum(dim=[1, 2]) / np.prod(xs[1:])\n",
        "\n",
        "\n",
        "def const_max(t, constant):\n",
        "    other = torch.ones_like(t) * constant\n",
        "    return torch.max(t, other)\n",
        "\n",
        "\n",
        "def const_min(t, constant):\n",
        "    other = torch.ones_like(t) * constant\n",
        "    return torch.min(t, other)\n",
        "\n",
        "\n",
        "def sample_from_discretized_mix_logistic(l, nr_mix):\n",
        "    ls = [s for s in l.shape]\n",
        "    xs = ls[:-1] + [3]\n",
        "    # unpack parameters\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = torch.reshape(l[:, :, :, nr_mix:], xs + [nr_mix * 3])\n",
        "    # sample mixture indicator from softmax\n",
        "    eps = torch.empty(logit_probs.shape, device=l.device).uniform_(1e-5, 1. - 1e-5)\n",
        "    amax = torch.argmax(logit_probs - torch.log(-torch.log(eps)), dim=3)\n",
        "    sel = F.one_hot(amax, num_classes=nr_mix).float()\n",
        "    sel = torch.reshape(sel, xs[:-1] + [1, nr_mix])\n",
        "    # select logistic parameters\n",
        "    means = (l[:, :, :, :, :nr_mix] * sel).sum(dim=4)\n",
        "    log_scales = const_max((l[:, :, :, :, nr_mix:nr_mix * 2] * sel).sum(dim=4), -7.)\n",
        "    coeffs = (torch.tanh(l[:, :, :, :, nr_mix * 2:nr_mix * 3]) * sel).sum(dim=4)\n",
        "    # sample from logistic & clip to interval\n",
        "    # we don't actually round to the nearest 8bit value when sampling\n",
        "    u = torch.empty(means.shape, device=means.device).uniform_(1e-5, 1. - 1e-5)\n",
        "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
        "    x0 = const_min(const_max(x[:, :, :, 0], -1.), 1.)\n",
        "    x1 = const_min(const_max(x[:, :, :, 1] + coeffs[:, :, :, 0] * x0, -1.), 1.)\n",
        "    x2 = const_min(const_max(x[:, :, :, 2] + coeffs[:, :, :, 1] * x0 + coeffs[:, :, :, 2] * x1, -1.), 1.)\n",
        "    return torch.cat([torch.reshape(x0, xs[:-1] + [1]), torch.reshape(x1, xs[:-1] + [1]), torch.reshape(x2, xs[:-1] + [1])], dim=3)\n",
        "\n",
        "\n",
        "class DmolNet(nn.Module):\n",
        "    def __init__(self, width, num_mixtures, low_bit=False):\n",
        "        super().__init__()\n",
        "        self.width = width\n",
        "        self.num_mixtures = num_mixtures\n",
        "        self.low_bit = low_bit\n",
        "        self.out_conv = nn.Conv2d(width, num_mixtures * 10, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def nll(self, px_z, x):\n",
        "        return discretized_mix_logistic_loss(x=x, l=self.forward(px_z), low_bit=self.low_bit)\n",
        "\n",
        "    def forward(self, px_z):\n",
        "        if not isinstance(px_z, torch.Tensor):\n",
        "            if isinstance(px_z, np.ndarray):\n",
        "                px_z = torch.from_numpy(px_z).to(device=self.out_conv.weight.device, dtype=self.out_conv.weight.dtype).contiguous()\n",
        "        xhat = self.out_conv(px_z)\n",
        "        return xhat.permute(0, 2, 3, 1)\n",
        "\n",
        "    def sample(self, px_z):\n",
        "        im = sample_from_discretized_mix_logistic(self.forward(px_z), self.num_mixtures)\n",
        "        xhat = (im + 1.0) * 127.5\n",
        "        xhat = xhat.detach().cpu().numpy()\n",
        "        xhat = np.minimum(np.maximum(0.0, xhat), 255.0).astype(np.uint8)\n",
        "        return xhat\n",
        "\n",
        "\n",
        "def log_prob_from_logits(x):\n",
        "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
        "    axis = len(x.shape) - 1\n",
        "    m = x.max(dim=axis, keepdim=True)[0]\n",
        "    return x - m - torch.log(torch.exp(x - m).sum(dim=axis, keepdim=True))\n",
        "\n",
        "\n",
        "def mpi_size():\n",
        "    return MPI.COMM_WORLD.Get_size()\n",
        "\n",
        "\n",
        "# def mpi_rank():\n",
        "#     return MPI.COMM_WORLD.Get_rank()\n",
        "def mpi_rank():\n",
        "    return 0  # 단일 GPU 또는 CPU 실행용\n",
        "\n",
        "\n",
        "# def compute_mpi_topology():\n",
        "#     world_size = mpi_size()\n",
        "#     global_rank = mpi_rank()\n",
        "#     # compute num_nodes\n",
        "#     if world_size % 8 == 0:\n",
        "#         num_nodes = world_size // 8\n",
        "#     else:\n",
        "#         num_nodes = world_size // 8 + 1\n",
        "#     # compute gpus_per_nodes\n",
        "#     if world_size > 1:\n",
        "#         gpus_per_node = max(world_size // num_nodes, 1)\n",
        "#     else:\n",
        "#         gpus_per_node = 1\n",
        "#     # local rank\n",
        "#     local_rank = global_rank % gpus_per_node\n",
        "\n",
        "#     return world_size, local_rank, global_rank\n",
        "def compute_mpi_topology():\n",
        "    return 1, 0, 0  # mpi_size, local_rank, rank\n",
        "\n",
        "\n",
        "# def setup_mpi(H):\n",
        "#     H.mpi_size, H.local_rank, H.rank = compute_mpi_topology()\n",
        "#     os.environ[\"RANK\"] = str(H.rank)\n",
        "#     os.environ[\"WORLD_SIZE\"] = str(H.mpi_size)\n",
        "#     os.environ[\"MASTER_PORT\"] = str(H.port)\n",
        "#     # os.environ[\"NCCL_LL_THRESHOLD\"] = \"0\"\n",
        "#     os.environ[\"MASTER_ADDR\"] = MPI.COMM_WORLD.bcast(socket.gethostname(), root=0)\n",
        "#     # 처음 한 번만 초기화\n",
        "#     if not dist.is_initialized():\n",
        "#       torch.cuda.set_device(H.local_rank)\n",
        "#       dist.init_process_group(backend='nccl', init_method=\"env://\")   # remove f''\n",
        "def setup_mpi(H):\n",
        "    H.mpi_size, H.local_rank, H.rank = 1, 0, 0  # 단일 노드 설정\n",
        "    # dist.init_process_group 제거\n",
        "\n",
        "\n",
        "def mkdir_p(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "def setup_save_dirs(H):\n",
        "    H.save_dir = os.path.join(H.save_dir, H.desc)\n",
        "    mkdir_p(H.save_dir)\n",
        "    H.logdir = os.path.join(H.save_dir, 'log')\n",
        "\n",
        "\n",
        "def logger(log_prefix):\n",
        "    'Prints the arguments out to stdout, .txt, and .jsonl files'\n",
        "    jsonl_path = f'{log_prefix}.jsonl'\n",
        "    txt_path = f'{log_prefix}.txt'\n",
        "\n",
        "    def log(*args, pprint=False, **kwargs):\n",
        "        # if mpi_rank() != 0:\n",
        "        #     return\n",
        "        t = time.ctime()\n",
        "        argdict = {'time': t}\n",
        "        if len(args) > 0:\n",
        "            argdict['message'] = ' '.join([str(x) for x in args])\n",
        "        argdict.update(kwargs)\n",
        "\n",
        "        txt_str = []\n",
        "        args_iter = sorted(argdict) if pprint else argdict\n",
        "        for k in args_iter:\n",
        "            val = argdict[k]\n",
        "            if isinstance(val, np.ndarray):\n",
        "                val = val.tolist()\n",
        "            elif isinstance(val, np.integer):\n",
        "                val = int(val)\n",
        "            elif isinstance(val, np.floating):\n",
        "                val = float(val)\n",
        "            argdict[k] = val\n",
        "            if isinstance(val, float):\n",
        "                val = f'{val:.5f}'\n",
        "            txt_str.append(f'{k}: {val}')\n",
        "        txt_str = ', '.join(txt_str)\n",
        "\n",
        "        if pprint:\n",
        "            json_str = json.dumps(argdict, sort_keys=True)\n",
        "            txt_str = json.dumps(argdict, sort_keys=True, indent=4)\n",
        "        else:\n",
        "            json_str = json.dumps(argdict)\n",
        "        print(txt_str, flush=True)\n",
        "\n",
        "        with open(txt_path, \"a+\") as f:\n",
        "            print(txt_str, file=f, flush=True)\n",
        "        with open(jsonl_path, \"a+\") as f:\n",
        "            print(json_str, file=f, flush=True)\n",
        "    return log\n",
        "\n",
        "\n",
        "def set_up_hyperparams(s=None):\n",
        "    H = Hyperparams()\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser = add_vae_arguments(parser)\n",
        "    parse_args_and_update_hparams(H, parser, s=s)\n",
        "    setup_mpi(H)\n",
        "    setup_save_dirs(H)\n",
        "    logprint = logger(H.logdir)\n",
        "    for i, k in enumerate(sorted(H)):\n",
        "        logprint(type='hparam', key=k, value=H[k])\n",
        "    np.random.seed(H.seed)\n",
        "    torch.manual_seed(H.seed)\n",
        "    torch.cuda.manual_seed(H.seed)\n",
        "    logprint('traning model', H.desc, 'on', H.dataset)\n",
        "    return H, logprint\n",
        "\n",
        "\n",
        "def linear_warmup(warmup_iters):\n",
        "    def f(iteration):\n",
        "        return iteration / warmup_iters if iteration < warmup_iters else 1.0\n",
        "    return f\n",
        "\n",
        "\n",
        "def load_vaes(encoder, decoder, image_size, logprint):\n",
        "    mpi_size, local_rank, rank = compute_mpi_topology()\n",
        "    torch.cuda.set_device(local_rank)\n",
        "\n",
        "    vae = VAE(encoder, decoder, image_size).cuda(local_rank)\n",
        "    ema_vae = VAE(encoder, decoder, image_size).cuda(local_rank)\n",
        "    ema_vae.load_state_dict(vae.state_dict())\n",
        "    ema_vae.requires_grad_(True)\n",
        "\n",
        "    # if mpi_size > 1:\n",
        "    #     vae = DistributedDataParallel(vae, device_ids=[local_rank], output_device=local_rank)\n",
        "    # validate parameter names\n",
        "    named = list(vae.named_parameters())\n",
        "    all_params = list(vae.parameters())\n",
        "    if len(named) != len(all_params):\n",
        "        raise ValueError(\"Some parameters are unnamed-DDP requires all params to be named\")\n",
        "    total_params = 0\n",
        "    for name, p in vae.named_parameters():\n",
        "        total_params += np.prod(p.shape)\n",
        "    logprint(total_params=total_params, readable=f'{total_params:,}')\n",
        "    return vae, ema_vae\n",
        "\n",
        "\n",
        "def load_opt(H, vae, logprint):\n",
        "    optimizer = AdamW(vae.parameters(), weight_decay=H.wd, lr=H.lr, betas=(H.adam_beta1, H.adam_beta2))\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=linear_warmup(H.warmup_iters))\n",
        "\n",
        "    starting_epoch = 0\n",
        "    iterate = 0\n",
        "    cur_eval_loss = float('inf')\n",
        "    logprint('optimizer & scheduler initialized', epoch=starting_epoch, iterate=iterate, eval_loss=cur_eval_loss)\n",
        "    return optimizer, scheduler, starting_epoch, iterate, cur_eval_loss\n",
        "\n",
        "\n",
        "# def allreduce(x, average):\n",
        "#     if mpi_size() > 1:\n",
        "#         dist.all_reduce(x, dist.ReduceOp.SUM)\n",
        "#     return x / mpi_size() if average else x\n",
        "def allreduce(x, average):\n",
        "    return x  # 단일 GPU라서 allreduce 불필요\n",
        "\n",
        "\n",
        "def get_cpu_stats_over_ranks(stat_dict):\n",
        "    keys = sorted(stat_dict.keys())\n",
        "    stats = torch.stack([torch.as_tensor(stat_dict[k]).detach().cuda().float() for k in keys])\n",
        "    allreduced = allreduce(stats, average=True).cpu()\n",
        "    return {k: allreduced[i].item() for (i, k) in enumerate(keys)}\n",
        "\n",
        "\n",
        "def save_model(path, vae, ema_vae, optimizer, H):\n",
        "    torch.save(vae.state_dict(), f'{path}-model.th')\n",
        "    torch.save(ema_vae.state_dict(), f'{path}-model-ema.th')\n",
        "    torch.save(optimizer.state_dict(), f'{path}-opt.th')\n",
        "    from_log = os.path.join(H.save_dir, 'log.jsonl')\n",
        "    to_log = f'{os.path.dirname(path)}/{os.path.basename(path)}-log.jsonl'\n",
        "    subprocess.check_output(['cp', from_log, to_log])\n",
        "\n",
        "\n",
        "def accumulate_stats(stats, frequency):\n",
        "    z = {}\n",
        "    for k in stats[-1]:\n",
        "        if k in ['distortion_nans', 'rate_nans', 'skipped_updates', 'gcskip']:\n",
        "            z[k] = np.sum([a[k] for a in stats[-frequency:]])\n",
        "        elif k == 'grad_norm':\n",
        "            vals = [a[k] for a in stats[-frequency:]]\n",
        "            finites = np.array(vals)[np.isfinite(vals)]\n",
        "            if len(finites) == 0:\n",
        "                z[k] = 0.0\n",
        "            else:\n",
        "                z[k] = np.max(finites)\n",
        "        elif k == 'elbo':\n",
        "            vals = [a[k] for a in stats[-frequency:]]\n",
        "            finites = np.array(vals)[np.isfinite(vals)]\n",
        "            z['elbo'] = np.mean(vals)\n",
        "            z['elbo_filtered'] = np.mean(finites)\n",
        "        elif k == 'iter_time':\n",
        "            z[k] = stats[-1][k] if len(stats) < frequency else np.mean([a[k] for a in stats[-frequency:]])\n",
        "        else:\n",
        "            z[k] = np.mean([a[k] for a in stats[-frequency:]])\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, dim_qk, heads=4):\n",
        "        super().__init__()\n",
        "        self.dim = dim_qk\n",
        "        self.heads = heads\n",
        "        self.scale = (dim_qk // heads) ** -0.5\n",
        "\n",
        "        self.to_q = nn.Linear(dim_qk, dim_qk)\n",
        "        self.to_k = nn.Linear(dim_qk, dim_qk)\n",
        "        self.to_v = nn.Linear(dim_qk, dim_qk)\n",
        "        self.to_out = nn.Linear(dim_qk, dim_qk)\n",
        "\n",
        "    def forward(self, x_q, x_kv):\n",
        "        B, C, H, W = x_q.shape\n",
        "        N = H * W\n",
        "\n",
        "        q = self.to_q(x_q.flatten(2).permute(0, 2, 1))  # B, N, C\n",
        "        k = self.to_k(x_kv.flatten(2).permute(0, 2, 1))\n",
        "        v = self.to_v(x_kv.flatten(2).permute(0, 2, 1))\n",
        "\n",
        "        q = q.view(B, N, self.heads, C // self.heads).transpose(1, 2)  # B, heads, N, d\n",
        "        k = k.view(B, N, self.heads, C // self.heads).transpose(1, 2)\n",
        "        v = v.view(B, N, self.heads, C // self.heads).transpose(1, 2)\n",
        "\n",
        "        attn = torch.softmax(torch.matmul(q, k.transpose(-1, -2)) * self.scale, dim=-1)\n",
        "        out = torch.matmul(attn, v)  # B, heads, N, d\n",
        "        out = out.transpose(1, 2).contiguous().view(B, N, C)  # B, N, C\n",
        "        out = self.to_out(out).permute(0, 2, 1).view(B, C, H, W)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00dFsYPq5m8"
      },
      "source": [
        "# Block.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3tNobjeSq8qD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch, downsample=False, residual=True, zero_last=False, use_attn=False, use_gated_residual=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(mid_ch, mid_ch, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(mid_ch, mid_ch, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(mid_ch, out_ch, kernel_size=1)\n",
        "\n",
        "        if zero_last:\n",
        "            nn.init.zeros_(self.conv4.weight)\n",
        "            if self.conv4.bias is not None:\n",
        "                nn.init.zeros_(self.conv4.bias)\n",
        "\n",
        "        self.use_residual = residual\n",
        "        self.use_downsample = downsample\n",
        "        self.down = nn.AvgPool2d(kernel_size=2) if downsample else nn.Identity()\n",
        "\n",
        "        self.use_attn = use_attn\n",
        "        self.use_gated_residual = use_gated_residual\n",
        "\n",
        "        if self.use_attn:\n",
        "            self.attn = CrossAttention(out_ch)\n",
        "            if self.use_gated_residual:\n",
        "                self.gate_conv = nn.Conv2d(out_ch, out_ch, kernel_size=1)\n",
        "\n",
        "    def gated_residual(self, x, attn_out):\n",
        "        gate = torch.sigmoid(self.gate_conv(x))\n",
        "        return x + gate * attn_out\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.gelu(x)\n",
        "        out = self.conv1(out)\n",
        "        out = F.gelu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = F.gelu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = F.gelu(out)\n",
        "        out = self.conv4(out)\n",
        "\n",
        "        if self.use_residual:\n",
        "            out = out + x\n",
        "\n",
        "        out = self.down(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5QUS-EEq-e_"
      },
      "source": [
        "# Encoder.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KTFLVv7YrAYE"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, image_channels, base_width, custom_width_str, block_str, bottleneck_multiple):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_conv = nn.Conv2d(image_channels, base_width, kernel_size=3, padding=1)\n",
        "        self.widths = get_width_settings(base_width, custom_width_str)\n",
        "        block_config = parse_layer_string(block_str)\n",
        "\n",
        "        enc_blocks = []\n",
        "        for res, down_rate in block_config:\n",
        "            width = self.widths[res]\n",
        "            mid_width = int(width * bottleneck_multiple)\n",
        "\n",
        "            # 원본 방식: 모든 Block은 in_ch == out_ch == width\n",
        "            block = Block(\n",
        "                in_ch=width,\n",
        "                mid_ch=mid_width,\n",
        "                out_ch=width,\n",
        "                downsample=(down_rate is not None),\n",
        "                residual=True,\n",
        "                use_attn=True,\n",
        "                use_gated_residual=True\n",
        "            )\n",
        "            enc_blocks.append(block)\n",
        "\n",
        "        self.enc_blocks = nn.ModuleList(enc_blocks)\n",
        "        self.block_resolutions = [res for res, _ in block_config]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        x = self.in_conv(x)\n",
        "\n",
        "        feats = {}\n",
        "        feats[x.shape[2]] = x  # 초기 해상도\n",
        "\n",
        "        for block, res in zip(self.enc_blocks, self.block_resolutions):\n",
        "            # 🔥 원본 방식: Block 입력 전에 채널 맞춰줌\n",
        "            if x.shape[1] != self.widths[res]:\n",
        "                x = pad_channels(x, self.widths[res])\n",
        "\n",
        "            x = block(x)\n",
        "            feats[res] = x\n",
        "\n",
        "        return feats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aBv35dVrCPK"
      },
      "source": [
        "# DecBlock.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bBLKf5vxuTe"
      },
      "outputs": [],
      "source": [
        "class DecBlock(nn.Module):\n",
        "    def __init__(self, res, mixin, width, zdim, bottleneck_multiple, n_blocks=1):\n",
        "        super().__init__()\n",
        "        self.res = res\n",
        "        self.mixin = mixin\n",
        "        self.width = width\n",
        "        self.zdim = zdim\n",
        "\n",
        "        cond_width = int(width * bottleneck_multiple)\n",
        "\n",
        "        self.enc = Block(width * 2, cond_width, zdim * 2, residual=False)\n",
        "        self.prior = Block(width, cond_width, zdim * 2 + width, residual=False, zero_last=True)\n",
        "\n",
        "        self.z_proj = nn.Conv2d(zdim, width, kernel_size=1)\n",
        "        self.z_proj.weight.data *= np.sqrt(1 / n_blocks)\n",
        "\n",
        "        self.resnet = Block(width, cond_width, width, residual=True)\n",
        "        self.resnet.conv4.weight.data *= np.sqrt(1 / n_blocks)\n",
        "\n",
        "    def z_fn(self, z):\n",
        "        return self.z_proj(z)\n",
        "\n",
        "    def get_inputs(self, xs, activations):\n",
        "        acts = activations[self.res]\n",
        "        x = xs.get(self.res, torch.zeros_like(acts))\n",
        "\n",
        "        # 🔥 interpolate acts if shape mismatch\n",
        "        if acts.shape[2:] != x.shape[2:]:\n",
        "            acts = F.interpolate(acts, size=x.shape[2:], mode='nearest')\n",
        "\n",
        "        if acts.shape[0] != x.shape[0]:\n",
        "            x = x.repeat(acts.shape[0], 1, 1, 1)\n",
        "\n",
        "        return x, acts\n",
        "\n",
        "    def sample(self, x, acts):\n",
        "        qm, qv = self.enc(torch.cat([x, acts], dim=1)).chunk(2, dim=1)\n",
        "        feats = self.prior(x)\n",
        "        pm, pv, xpp = feats[:, :self.zdim], feats[:, self.zdim:self.zdim*2], feats[:, self.zdim*2:]\n",
        "        x = x + xpp\n",
        "        z = draw_gaussian_diag_samples(qm, qv)\n",
        "        kl = gaussian_analytical_kl(qm, pm, qv, pv)\n",
        "        return z, x, kl\n",
        "\n",
        "    def sample_uncond(self, x, t=None, lvs=None):\n",
        "        feats = self.prior(x)\n",
        "        pm, pv, xpp = feats[:, :self.zdim], feats[:, self.zdim:self.zdim*2], feats[:, self.zdim*2:]\n",
        "        x = x + xpp\n",
        "        if lvs is not None:\n",
        "            z = lvs\n",
        "        else:\n",
        "            if t is not None:\n",
        "                pv = pv + torch.ones_like(pv) * np.log(t)\n",
        "            z = draw_gaussian_diag_samples(pm, pv)\n",
        "        return z, x\n",
        "\n",
        "    def forward(self, xs, activations, get_latents=False):\n",
        "        x, acts = self.get_inputs(xs, activations)\n",
        "        if self.mixin is not None:\n",
        "            mix = xs[self.mixin][:, :x.shape[1], ...]\n",
        "            scale = self.res // self.mixin\n",
        "            x = x + F.interpolate(mix, scale_factor=scale)\n",
        "\n",
        "        z, x, kl = self.sample(x, acts)\n",
        "        x = x + self.z_fn(z)\n",
        "        x = self.resnet(x)\n",
        "        xs[self.res] = x\n",
        "\n",
        "        if get_latents:\n",
        "            return xs, dict(z=z.detach(), kl=kl)\n",
        "        return xs, dict(kl=kl)\n",
        "\n",
        "    def forward_uncond(self, xs, t=None, lvs=None):\n",
        "        if self.res in xs:\n",
        "            x = xs[self.res]\n",
        "        else:\n",
        "            ref = xs[list(xs.keys())[0]]\n",
        "            x = torch.zeros(ref.shape[0], self.width, self.res, self.res, device=ref.device)\n",
        "\n",
        "        if self.mixin is not None:\n",
        "            mix = xs[self.mixin][:, :x.shape[1], ...]\n",
        "            scale = self.res // self.mixin\n",
        "            x = x + F.interpolate(mix, scale_factor=scale)\n",
        "\n",
        "        z, x = self.sample_uncond(x, t, lvs=lvs)\n",
        "        x = x + self.z_fn(z)\n",
        "        x = self.resnet(x)\n",
        "        xs[self.res] = x\n",
        "        return xs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdwof1nctUvF"
      },
      "source": [
        "# Decoder.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7VNEpwWdyhGC"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, width_map, zdim, bottleneck_multiple,\n",
        "                 output_res, block_str, num_mixtures, low_bit=False):\n",
        "        super().__init__()\n",
        "        self.output_res = output_res\n",
        "        self.width_map = width_map\n",
        "        blocks = parse_layer_string(block_str)\n",
        "        n_blocks = len(blocks)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            DecBlock(\n",
        "                res=res,\n",
        "                mixin=mixin,\n",
        "                width=width_map[res],\n",
        "                zdim=zdim,\n",
        "                bottleneck_multiple=bottleneck_multiple,\n",
        "                n_blocks=n_blocks\n",
        "            )\n",
        "            for res, mixin in blocks\n",
        "        ])\n",
        "\n",
        "        self.bias_xs = nn.ParameterDict({\n",
        "            str(res): nn.Parameter(torch.zeros(1, width_map[res], res, res))\n",
        "            for res, _ in blocks\n",
        "        })\n",
        "\n",
        "        out_width = width_map[output_res]\n",
        "        self.gain = nn.Parameter(torch.ones(1, out_width, 1, 1))\n",
        "        self.bias = nn.Parameter(torch.zeros(1, out_width, 1, 1))\n",
        "\n",
        "        # 🔥 DmolNet 붙이기\n",
        "        self.out_net = DmolNet(width=out_width, num_mixtures=num_mixtures, low_bit=low_bit)\n",
        "\n",
        "    def final_fn(self, x):\n",
        "        return x * self.gain + self.bias\n",
        "\n",
        "    def forward(self, activations, get_latents=False):\n",
        "        B = next(iter(activations.values())).shape[0]\n",
        "        xs = {\n",
        "            int(res): bias.repeat(B, 1, 1, 1)\n",
        "            for res, bias in self.bias_xs.items()\n",
        "        }\n",
        "\n",
        "        stats = []\n",
        "        for block in self.blocks:\n",
        "            xs, block_stat = block(xs, activations, get_latents=get_latents)\n",
        "            stats.append(block_stat)\n",
        "\n",
        "        out = self.final_fn(xs[self.output_res])\n",
        "        return out, stats  # 🔥 DmolNet 통과시켜 반환\n",
        "\n",
        "    def forward_uncond(self, n, t=None):\n",
        "        xs = {\n",
        "            int(res): bias.repeat(n, 1, 1, 1)\n",
        "            for res, bias in self.bias_xs.items()\n",
        "        }\n",
        "\n",
        "        for idx, block in enumerate(self.blocks):\n",
        "            temp = t[idx] if isinstance(t, list) else t\n",
        "            xs = block.forward_uncond(xs, t=temp)\n",
        "\n",
        "        out = self.final_fn(xs[self.output_res])\n",
        "        return self.out_net.sample(out)  # 🔥 DmolNet 통해 샘플링\n",
        "\n",
        "    def forward_manual_latents(self, n, latents, t=None):\n",
        "        xs = {\n",
        "            int(res): bias.repeat(n, 1, 1, 1)\n",
        "            for res, bias in self.bias_xs.items()\n",
        "        }\n",
        "\n",
        "        for block, lvs in itertools.zip_longest(self.blocks, latents):\n",
        "            xs = block.forward_uncond(xs, t=t, lvs=lvs)\n",
        "\n",
        "        out = self.final_fn(xs[self.output_res])\n",
        "        return self.out_net.sample(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zcvw8q3rKIA"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EhKPYVTUrLyM"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder, image_size):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.image_size = image_size  # 예: 32 (CIFAR)\n",
        "\n",
        "    def forward(self, x, x_target):\n",
        "        activations = self.encoder(x)  # 해상도별 feature map 반환\n",
        "        px_z, stats = self.decoder(activations, get_latents=True)\n",
        "\n",
        "        distortion_per_pixel = self.decoder.out_net.nll(px_z, x_target)\n",
        "        rate_per_pixel = torch.zeros_like(distortion_per_pixel)\n",
        "\n",
        "        # 각 블록에서 KL divergence를 누적\n",
        "        for stat in stats:\n",
        "            rate_per_pixel += stat['kl'].sum(dim=(1, 2, 3))\n",
        "\n",
        "        ndims = np.prod(x.shape[1:])  # 픽셀 수\n",
        "        rate_per_pixel /= ndims\n",
        "        elbo = (distortion_per_pixel + rate_per_pixel).mean()\n",
        "\n",
        "        return {\n",
        "            'elbo': elbo,\n",
        "            'distortion': distortion_per_pixel.mean(),\n",
        "            'rate': rate_per_pixel.mean()\n",
        "        }\n",
        "\n",
        "    def forward_get_latents(self, x):\n",
        "        activations = self.encoder(x)\n",
        "        _, stats = self.decoder(activations, get_latents=True)\n",
        "        return stats\n",
        "\n",
        "    def forward_uncond_samples(self, n_batch, t=None):\n",
        "        # Removed redundant call to self.decoder.out_net.sample\n",
        "        return self.decoder.forward_uncond(n_batch, t=t)\n",
        "\n",
        "    def forward_samples_set_latents(self, n_batch, latents, t=None):\n",
        "        # Removed redundant call to self.decoder.out_net.sample\n",
        "        return self.decoder.forward_manual_latents(n_batch, latents, t=t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU9IY_8Dtrn1"
      },
      "source": [
        "# Train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HUcCoUjftsrX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "S22cWOhecjnG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-06-09 09:15:53--  https://data.brainchip.com/dataset-mirror/cifar10/cifar-10-python.tar.gz\n",
            "Resolving data.brainchip.com (data.brainchip.com)... 146.59.209.152, 2001:41d0:301::31\n",
            "Connecting to data.brainchip.com (data.brainchip.com)|146.59.209.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M   279KB/s    in 6m 12s  \n",
            "\n",
            "2025-06-09 09:22:07 (447 KB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.brainchip.com/dataset-mirror/cifar10/cifar-10-python.tar.gz\n",
        "!tar -xf cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Upwziptutp",
        "outputId": "832b9b61-b1ab-4f7c-dc3f-87f91c9708ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-06-09 09:22:09--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz.1’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  2.61MB/s    in 61s     \n",
            "\n",
            "2025-06-09 09:23:12 (2.66 MB/s) - ‘cifar-10-python.tar.gz.1’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xf cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GAMZ9dm2twff",
        "outputId": "1b4d855f-1bbd-4e83-e037-0fd79160460c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: adam_beta1, value: 0.90000\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: adam_beta2, value: 0.90000\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: data_root, value: ../vdvae_colab\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: dataset, value: cifar10\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: desc, value: test\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: ema_rate, value: 0.99980\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: epochs_per_eval, value: 10\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: epochs_per_eval_save, value: 20\n",
            "time: Tue Jun 10 00:18:10 2025, type: hparam, key: epochs_per_probe, value: None\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: grad_clip, value: 200.00000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: iters_per_ckpt, value: 25000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: iters_per_images, value: 10000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: iters_per_print, value: 1000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: iters_per_save, value: 1500\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: local_rank, value: 0\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: logdir, value: ./saved_models\\test\\log\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: lr, value: 0.00020\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: lr_prior, value: 0.00015\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: max_iters, value: 1400\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: mpi_size, value: 1\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: n_batch, value: 32\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: num_epochs, value: 1\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: num_images_visualize, value: 10\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: num_temperatures_visualize, value: 3\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: num_variables_visualize, value: 7\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: port, value: 29500\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: rank, value: 0\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: restore_ema_path, value: None\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: restore_log_path, value: None\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: restore_optimizer_path, value: None\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: restore_path, value: None\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: save_dir, value: ./saved_models\\test\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: seed, value: 0\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: skip_threshold, value: 400.00000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: temperature, value: 1.00000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: test_eval, value: False\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: warmup_iters, value: 100\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: wd, value: 0.01000\n",
            "time: Tue Jun 10 00:18:11 2025, type: hparam, key: wd_prior, value: 0.00000\n",
            "time: Tue Jun 10 00:18:11 2025, message: traning model test on cifar10\n",
            "time: Tue Jun 10 00:18:12 2025, total_params: 64424036, readable: 64,424,036\n",
            "time: Tue Jun 10 00:18:15 2025, message: optimizer & scheduler initialized, epoch: 0, iterate: 0, eval_loss: inf\n",
            "time: Tue Jun 10 00:18:32 2025, model: test, type: train_loss, lr: 0.00000, epoch: 0, step: 0, distortion: 6.17047, distortion_nans: 0.00000, elbo: 6.89220, elbo_filtered: 6.89220, rate: 0.72173, rate_nans: 0.00000, skipped_updates: 0, iter_time: 16.85012, grad_norm: 4.12390\n",
            "time: Tue Jun 10 00:18:37 2025, message: printing samples to ./saved_models\\test/samples-0.png\n",
            "time: Tue Jun 10 00:18:58 2025, model: test, type: train_loss, lr: 0.00000, epoch: 0, step: 1, distortion: 6.24141, distortion_nans: 0.00000, elbo: 6.96314, elbo_filtered: 6.96314, rate: 0.72174, rate_nans: 0.00000, skipped_updates: 0, iter_time: 20.24941, grad_norm: 4.23124\n",
            "time: Tue Jun 10 00:19:03 2025, message: printing samples to ./saved_models\\test/samples-1.png\n",
            "time: Tue Jun 10 00:21:00 2025, model: test, type: train_loss, lr: 0.00002, epoch: 0, step: 8, distortion: 6.23524, distortion_nans: 0.00000, elbo: 6.94372, elbo_filtered: 6.94372, rate: 0.70848, rate_nans: 0.00000, skipped_updates: 0, iter_time: 15.97966, grad_norm: 4.37137\n",
            "time: Tue Jun 10 00:21:05 2025, message: printing samples to ./saved_models\\test/samples-8.png\n",
            "time: Tue Jun 10 00:23:05 2025, model: test, type: train_loss, lr: 0.00003, epoch: 0, step: 16, distortion: 6.18197, distortion_nans: 0.00000, elbo: 6.84827, elbo_filtered: 6.84827, rate: 0.66630, rate_nans: 0.00000, skipped_updates: 0, iter_time: 15.48513, grad_norm: 4.37137\n",
            "time: Tue Jun 10 00:23:09 2025, message: printing samples to ./saved_models\\test/samples-16.png\n",
            "time: Tue Jun 10 00:27:10 2025, model: test, type: train_loss, lr: 0.00007, epoch: 0, step: 32, distortion: 5.95798, distortion_nans: 0.00000, elbo: 6.46527, elbo_filtered: 6.46527, rate: 0.50729, rate_nans: 0.00000, skipped_updates: 0, iter_time: 14.71243, grad_norm: 6.16550\n",
            "time: Tue Jun 10 00:27:14 2025, message: printing samples to ./saved_models\\test/samples-32.png\n",
            "time: Tue Jun 10 00:35:05 2025, model: test, type: train_loss, lr: 0.00013, epoch: 0, step: 64, distortion: 5.58474, distortion_nans: 0.00000, elbo: 5.87411, elbo_filtered: 5.87411, rate: 0.28937, rate_nans: 0.00000, skipped_updates: 0, iter_time: 19.68074, grad_norm: 34.26453\n",
            "time: Tue Jun 10 00:35:10 2025, message: printing samples to ./saved_models\\test/samples-64.png\n",
            "time: Tue Jun 10 00:51:42 2025, model: test, type: train_loss, lr: 0.00020, epoch: 0, step: 128, distortion: 5.18952, distortion_nans: 0.00000, elbo: 5.36573, elbo_filtered: 5.36573, rate: 0.17620, rate_nans: 0.00000, skipped_updates: 0, iter_time: 12.79381, grad_norm: 34.26453\n",
            "time: Tue Jun 10 00:51:46 2025, message: printing samples to ./saved_models\\test/samples-128.png\n",
            "time: Tue Jun 10 01:19:48 2025, model: test, type: train_loss, lr: 0.00020, epoch: 0, step: 256, distortion: 4.84781, distortion_nans: 0.00000, elbo: 4.97702, elbo_filtered: 4.97702, rate: 0.12921, rate_nans: 0.00000, skipped_updates: 0, iter_time: 15.41498, grad_norm: 57.32640\n",
            "time: Tue Jun 10 01:19:52 2025, message: printing samples to ./saved_models\\test/samples-256.png\n",
            "time: Tue Jun 10 02:22:19 2025, model: test, type: train_loss, lr: 0.00020, epoch: 0, step: 512, distortion: 4.47534, distortion_nans: 0.00000, elbo: 4.59686, elbo_filtered: 4.59686, rate: 0.12152, rate_nans: 0.00000, skipped_updates: 0, iter_time: 14.15981, grad_norm: 125.38392\n",
            "time: Tue Jun 10 02:22:23 2025, message: printing samples to ./saved_models\\test/samples-512.png\n",
            "time: Tue Jun 10 04:31:41 2025, model: test, type: train_loss, lr: 0.00020, epoch: 0, step: 1000, distortion: 4.12371, distortion_nans: 0.00000, elbo: 4.27036, elbo_filtered: 4.27036, rate: 0.14665, rate_nans: 0.00000, skipped_updates: 0, iter_time: 15.14254, grad_norm: 167.74516\n",
            "time: Tue Jun 10 04:37:36 2025, model: test, type: train_loss, lr: 0.00020, epoch: 0, step: 1024, distortion: 4.06416, distortion_nans: 0.00000, elbo: 4.20182, elbo_filtered: 4.20182, rate: 0.13767, rate_nans: 0.00000, skipped_updates: 0, iter_time: 15.11721, grad_norm: 167.74516\n",
            "time: Tue Jun 10 04:37:41 2025, message: printing samples to ./saved_models\\test/samples-1024.png\n",
            "time: Tue Jun 10 06:09:41 2025, message: Reached max_iters=1400, stopping training.\n",
            "time: Tue Jun 10 06:09:45 2025, message: printing samples to ./saved_models\\test/samples-final-1400.png\n"
          ]
        }
      ],
      "source": [
        "def training_step(H, data_input, target, vae, ema_vae, optimizer, iterate):\n",
        "    t0 = time.time()\n",
        "    vae.zero_grad()\n",
        "    stats = vae.forward(data_input, target)\n",
        "\n",
        "    stats['elbo'].backward()\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(vae.parameters(), H.grad_clip).item()\n",
        "    distortion_nans = torch.isnan(stats['distortion']).sum()\n",
        "    rate_nans = torch.isnan(stats['rate']).sum()\n",
        "    stats.update(dict(rate_nans=0 if rate_nans == 0 else 1, distortion_nans=0 if distortion_nans == 0 else 1))\n",
        "    stats = get_cpu_stats_over_ranks(stats)\n",
        "\n",
        "    skipped_updates = 1\n",
        "    # only update if no rank has a nan and if the grad norm is below a specific threshold\n",
        "    if stats['distortion_nans'] == 0 and stats['rate_nans'] == 0 and (H.skip_threshold == -1 or grad_norm < H.skip_threshold):\n",
        "        optimizer.step()\n",
        "        skipped_updates = 0\n",
        "        for p1, p2 in zip(vae.parameters(), ema_vae.parameters()):\n",
        "            p2.data.mul_(H.ema_rate)\n",
        "            p2.data.add_(p1.data * (1 - H.ema_rate))\n",
        "    t1 = time.time()\n",
        "    stats.update(skipped_updates=skipped_updates, iter_time=t1 - t0, grad_norm=grad_norm)\n",
        "    return stats\n",
        "\n",
        "\n",
        "def eval_step(data_input, target, ema_vae):\n",
        "    with torch.no_grad():\n",
        "        stats = ema_vae.forward(data_input, target)\n",
        "    stats = get_cpu_stats_over_ranks(stats)\n",
        "    return stats\n",
        "\n",
        "\n",
        "def get_sample_for_visualization(data, preprocess_func, batch_size):\n",
        "    for x in DataLoader(data, batch_size=batch_size):\n",
        "        break\n",
        "    orig_image = x[0]\n",
        "    preprocessed = preprocess_func(x)[0]\n",
        "    return orig_image, preprocessed\n",
        "\n",
        "\n",
        "def train_loop(H, data_train, data_valid, preprocess_func, vae, ema_vae,\n",
        "               optimizer, scheduler, starting_epoch, iterate, cur_eval_loss, logprint):\n",
        "    train_sampler = DistributedSampler(data_train, num_replicas=H.mpi_size, rank=H.rank)\n",
        "    viz_batch_original, viz_batch_processed = get_sample_for_visualization(data_valid, preprocess_func, H.num_images_visualize) # Removed H.dataset as it's not used\n",
        "    early_evals = set([1] + [2 ** exp for exp in range(3, 14)])\n",
        "    stats = []\n",
        "    iters_since_starting = 0\n",
        "    H.ema_rate = torch.as_tensor(H.ema_rate).cuda()\n",
        "    for epoch in range(starting_epoch, H.num_epochs):\n",
        "        train_sampler.set_epoch(epoch)\n",
        "        for x in DataLoader(data_train, batch_size=H.n_batch, drop_last=True, pin_memory=True, sampler=train_sampler):\n",
        "            if H.max_iters > 0 and iterate >= H.max_iters:\n",
        "                logprint(f\"Reached max_iters={H.max_iters}, stopping training.\")\n",
        "                # iteration의 제일 마지막에는 항상 sample return\n",
        "                if H.rank == 0:\n",
        "                    write_images(H, ema_vae, viz_batch_original, viz_batch_processed,\n",
        "                                f'{H.save_dir}/samples-final-{iterate}.png', logprint)\n",
        "                return\n",
        "            data_input, target = preprocess_func(x)\n",
        "            training_stats = training_step(H, data_input, target, vae, ema_vae, optimizer, iterate)\n",
        "            stats.append(training_stats)\n",
        "            scheduler.step()\n",
        "            if iterate % H.iters_per_print == 0 or iters_since_starting in early_evals:\n",
        "                logprint(model=H.desc, type='train_loss', lr=scheduler.get_last_lr()[0], epoch=epoch, step=iterate, **accumulate_stats(stats, H.iters_per_print))\n",
        "\n",
        "            if iterate % H.iters_per_images == 0 or (iters_since_starting in early_evals and H.dataset != 'ffhq_1024') and H.rank == 0:\n",
        "                write_images(H, ema_vae, viz_batch_original, viz_batch_processed, f'{H.save_dir}/samples-{iterate}.png', logprint)\n",
        "\n",
        "            iterate += 1\n",
        "            iters_since_starting += 1\n",
        "\n",
        "            # 일정 시간마다 \"latest\" 체크포인트를 저장!\n",
        "            if iterate % H.iters_per_save == 0 and H.rank == 0:\n",
        "                if np.isfinite(stats[-1]['elbo']):\n",
        "                    logprint(model=H.desc, type='train_loss', epoch=epoch, step=iterate, **accumulate_stats(stats, H.iters_per_print))\n",
        "                    fp = os.path.join(H.save_dir, 'latest')\n",
        "                    logprint(f'Saving model@ {iterate} to {fp}')\n",
        "                    save_model(fp, vae, ema_vae, optimizer, H)\n",
        "\n",
        "            if iterate % H.iters_per_ckpt == 0 and H.rank == 0:\n",
        "                save_model(os.path.join(H.save_dir, f'iter-{iterate}'), vae, ema_vae, optimizer, H)\n",
        "\n",
        "        if epoch % H.epochs_per_eval == 0:\n",
        "            valid_stats = evaluate(H, ema_vae, data_valid, preprocess_func)\n",
        "            logprint(model=H.desc, type='eval_loss', epoch=epoch, step=iterate, **valid_stats)\n",
        "\n",
        "\n",
        "def evaluate(H, ema_vae, data_valid, preprocess_func):\n",
        "    stats_valid = []\n",
        "    valid_sampler = DistributedSampler(data_valid, num_replicas=H.mpi_size, rank=H.rank)\n",
        "    for x in DataLoader(data_valid, batch_size=H.n_batch, drop_last=True, pin_memory=True, sampler=valid_sampler):\n",
        "        data_input, target = preprocess_func(x)\n",
        "        stats_valid.append(eval_step(data_input, target, ema_vae))\n",
        "    vals = [a['elbo'] for a in stats_valid]\n",
        "    finites = np.array(vals)[np.isfinite(vals)]\n",
        "    stats = dict(n_batches=len(vals), filtered_elbo=np.mean(finites), **{k: np.mean([a[k] for a in stats_valid]) for k in stats_valid[-1]})\n",
        "    return stats\n",
        "\n",
        "\n",
        "def write_images(H, ema_vae, viz_batch_original, viz_batch_processed, fname, logprint):\n",
        "    zs = [s['z'].cuda() for s in ema_vae.forward_get_latents(viz_batch_processed)]\n",
        "    batches = [viz_batch_original.numpy()]\n",
        "    mb = viz_batch_processed.shape[0]\n",
        "    lv_points = np.floor(np.linspace(0, 1, H.num_variables_visualize + 2) * len(zs)).astype(int)[1:-1]\n",
        "    for i in lv_points:\n",
        "        reconstruction = ema_vae.decoder.forward_manual_latents(mb, zs[:i], t=0.1)\n",
        "        batches.append(reconstruction)\n",
        "    for t in [1.0, 0.9, 0.8, 0.7][:H.num_temperatures_visualize]:\n",
        "        sample = ema_vae.decoder.forward_uncond(mb, t=t)\n",
        "        batches.append(sample)\n",
        "    n_rows = len(batches)\n",
        "    im = np.concatenate(batches, axis=0).reshape((n_rows, mb, *viz_batch_processed.shape[1:])).transpose([0, 2, 1, 3, 4]).reshape([n_rows * viz_batch_processed.shape[1], mb * viz_batch_processed.shape[2], 3]).astype(np.uint8) # Explicitly cast to uint8\n",
        "    logprint(f'printing samples to {fname}')\n",
        "    imageio.imwrite(fname, im)\n",
        "\n",
        "\n",
        "def run_test_eval(H, ema_vae, data_test, preprocess_func, logprint):\n",
        "    print('evaluating')\n",
        "    stats = evaluate(H, ema_vae, data_test, preprocess_func)\n",
        "    print('test results')\n",
        "    for k in stats:\n",
        "        print(k, stats[k])\n",
        "    logprint(type='test_loss', **stats)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Encoder/Decoder/VAE 생성\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    encoder = Encoder(\n",
        "        image_channels=image_channels,\n",
        "        base_width=base_width,\n",
        "        custom_width_str=custom_width_str,\n",
        "        block_str=encblock_str,\n",
        "        bottleneck_multiple=bottleneck_multiple\n",
        "    )\n",
        "    decoder = Decoder(\n",
        "        width_map=encoder.widths,\n",
        "        zdim=zdim,\n",
        "        bottleneck_multiple=bottleneck_multiple,\n",
        "        output_res=image_size,\n",
        "        block_str=decblock_str,\n",
        "        num_mixtures=num_mixtures,\n",
        "        low_bit=False\n",
        "    )\n",
        "\n",
        "    H, logprint = set_up_hyperparams(s=[])\n",
        "    H.device = device\n",
        "    H, data_train, data_valid_or_test, preprocess_func = set_up_data(H)\n",
        "    vae, ema_vae = load_vaes(encoder, decoder, image_size, logprint)\n",
        "\n",
        "    # 저장된 checkpoint에서 학습을 다시 시작하는 경우\n",
        "    # load vae parameter\n",
        "    if H.restore_path is not None:\n",
        "        model_ckpt = f\"{H.restore_path}-model.th\"\n",
        "        ckpt_vae = torch.load(model_ckpt, map_location=H.device)\n",
        "        vae.load_state_dict(ckpt_vae)\n",
        "        vae = vae.to(device)\n",
        "        # load ema_vae parameter\n",
        "        if H.restore_ema_path is not None:\n",
        "            ema_ckpt = f\"{H.restore_ema_path}-model-ema.th\"\n",
        "            ckpt_ema = torch.load(ema_ckpt, map_location=H.device)\n",
        "            ema_vae.load_state_dict(ckpt_ema)\n",
        "            ema_vae = ema_vae.to(H.device)\n",
        "        print(f\">> Loaded model & EMA from {H.restore_path}.\")\n",
        "    else:\n",
        "        vae = vae.to(device)\n",
        "        ema_vae = ema_vae.to(device)\n",
        "\n",
        "    # generate optimizer & load optimizer\n",
        "    optimizer, scheduler, starting_epoch, iterate, cur_eval_loss = load_opt(H, vae, logprint)\n",
        "    if H.restore_optimizer_path is not None:\n",
        "        optimizer_ckpt = torch.load(H.restore_optimizer_path, map_location=H.device)\n",
        "        optimizer.load_state_dict(optimizer_ckpt)\n",
        "        print(f\">> Loaded optimizer state from {H.restore_optimizer_path}\")\n",
        "\n",
        "    # 실제 evaluation & test loop\n",
        "    if H.test_eval:\n",
        "        run_test_eval(H, ema_vae, data_valid_or_test, preprocess_func, logprint)\n",
        "    else:\n",
        "        train_loop(H, data_train, data_valid_or_test, preprocess_func, vae, ema_vae,\n",
        "                   optimizer, scheduler, starting_epoch, iterate, cur_eval_loss, logprint)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
